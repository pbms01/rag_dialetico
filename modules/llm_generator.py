"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
CONTEXT BUILDER + LLM GENERATOR
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Constr√≥i contexto RAG otimizado e gera contesta√ß√£o via Claude API
"""

import os
from typing import Dict, List, Optional
import anthropic

from config.settings import Config
from config.prompts import SYSTEM_PROMPT, construir_prompt_usuario

class ContextBuilder:
    """Constr√≥i contexto RAG otimizado para o prompt"""
    
    def __init__(self):
        pass
    
    def construir_contexto(
        self,
        dados_peticao: Dict,
        resultado_rag: Dict
    ) -> Dict:
        """
        Organiza e otimiza o contexto RAG para gera√ß√£o
        
        Args:
            dados_peticao: Dados estruturados da peti√ß√£o inicial
            resultado_rag: Resultado do retrieval hier√°rquico
            
        Returns:
            Contexto estruturado pronto para o prompt
        """
        # Adicionar classifica√ß√£o aos dados da peti√ß√£o
        classificacao = resultado_rag['classificacao']
        dados_peticao['tipo_caso'] = classificacao['tipo_caso']
        dados_peticao['confianca'] = classificacao['confianca']
        
        # Organizar chunks por n√≠vel
        contexto = {
            'nivel_1': self._rankear_chunks(resultado_rag['nivel_1'])[:5],  # Top 5
            'nivel_2': self._rankear_chunks(resultado_rag['nivel_2'])[:10],  # Top 10
            'nivel_3': self._rankear_chunks(resultado_rag['nivel_3'])[:8],  # Top 8
            'especificos': self._extrair_chunks_especificos(
                resultado_rag['nivel_2'],
                dados_peticao['tipo_caso']
            )
        }
        
        return contexto
    
    def _rankear_chunks(self, chunks: List[Dict]) -> List[Dict]:
        """Reordena chunks por relev√¢ncia (j√° v√™m ordenados, mas pode refinar)"""
        # J√° v√™m ordenados por similaridade, mas podemos aplicar reranking adicional
        return chunks
    
    def _extrair_chunks_especificos(
        self,
        chunks_nivel_2: List[Dict],
        tipo_caso: str
    ) -> List[Dict]:
        """Extrai chunks com argumentos espec√≠ficos do tipo de caso"""
        # Filtrar chunks que s√£o do tipo de caso identificado
        especificos = [
            chunk for chunk in chunks_nivel_2
            if chunk['metadata'].get('tipo_lit') == tipo_caso
        ]
        return especificos[:5]  # Top 5


class LLMGenerator:
    """Gera contesta√ß√£o usando Claude API"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Inicializa gerador
        
        Args:
            api_key: Chave API Anthropic (usa vari√°vel de ambiente se None)
        """
        self.api_key = api_key or Config.ANTHROPIC_API_KEY
        
        if not self.api_key:
            raise ValueError(
                "ANTHROPIC_API_KEY n√£o encontrada. "
                "Configure a vari√°vel de ambiente ou passe como par√¢metro."
            )
        
        self.client = anthropic.Anthropic(api_key=self.api_key)
    
    def gerar_contestacao(
        self,
        dados_peticao: Dict,
        contexto_rag: Dict,
        temperatura: float = Config.DEFAULT_TEMPERATURE,
        top_k: int = Config.DEFAULT_TOP_K,
        max_tokens: int = Config.DEFAULT_MAX_TOKENS
    ) -> Dict:
        """
        Gera contesta√ß√£o via Claude API
        
        Args:
            dados_peticao: Dados estruturados da peti√ß√£o
            contexto_rag: Contexto RAG constru√≠do
            temperatura: Par√¢metro de temperatura (0.3-0.9)
            top_k: Par√¢metro top-k (20-60)
            max_tokens: Tokens m√°ximos para gera√ß√£o
            
        Returns:
            Dict com contesta√ß√£o gerada e metadados
        """
        print("\n" + "="*80)
        print("ü§ñ GERANDO CONTESTA√á√ÉO COM CLAUDE SONNET 4.5")
        print("="*80 + "\n")
        
        # Validar par√¢metros
        temperatura = max(Config.MIN_TEMPERATURE, min(temperatura, Config.MAX_TEMPERATURE))
        top_k = max(Config.MIN_TOP_K, min(top_k, Config.MAX_TOP_K))
        
        print(f"‚öôÔ∏è  Par√¢metros:")
        print(f"   Temperatura: {temperatura}")
        print(f"   Top-k: {top_k}")
        print(f"   Max tokens: {max_tokens}\n")
        
        # Construir prompts
        print("üìù Construindo prompts...")
        prompt_usuario = construir_prompt_usuario(dados_peticao, contexto_rag)
        
        # Estimar tokens (aproximado)
        tokens_estimados = (len(SYSTEM_PROMPT) + len(prompt_usuario)) // 4
        print(f"   Tokens estimados (input): ~{tokens_estimados:,}\n")
        
        # Chamar API
        print("üåê Chamando API Claude...")
        try:
            response = self.client.messages.create(
                model=Config.CLAUDE_MODEL,
                max_tokens=max_tokens,
                temperature=temperatura,
                top_k=top_k,
                system=SYSTEM_PROMPT,
                messages=[
                    {"role": "user", "content": prompt_usuario}
                ]
            )
            
            # Extrair resposta
            contestacao_texto = response.content[0].text
            
            # Metadados da gera√ß√£o
            metadados = {
                'model': Config.CLAUDE_MODEL,
                'temperatura': temperatura,
                'top_k': top_k,
                'input_tokens': response.usage.input_tokens,
                'output_tokens': response.usage.output_tokens,
                'stop_reason': response.stop_reason,
                'tipo_caso': dados_peticao.get('tipo_caso'),
                'confianca_classificacao': dados_peticao.get('confianca')
            }
            
            print(f"‚úÖ Gera√ß√£o conclu√≠da!")
            print(f"   Input tokens: {metadados['input_tokens']:,}")
            print(f"   Output tokens: {metadados['output_tokens']:,}")
            print(f"   Total tokens: {metadados['input_tokens'] + metadados['output_tokens']:,}\n")
            
            # Custo estimado (aproximado para Sonnet 4.5)
            custo_input = (metadados['input_tokens'] / 1_000_000) * 15  # $15/MTok
            custo_output = (metadados['output_tokens'] / 1_000_000) * 75  # $75/MTok
            custo_total = custo_input + custo_output
            
            print(f"üí∞ Custo estimado: ${custo_total:.4f}\n")
            
            print("="*80)
            print("‚úÖ CONTESTA√á√ÉO GERADA COM SUCESSO")
            print("="*80 + "\n")
            
            return {
                'contestacao': contestacao_texto,
                'metadados': metadados,
                'custo_estimado': custo_total,
                'sucesso': True
            }
            
        except anthropic.APIError as e:
            print(f"‚ùå Erro na API: {e}\n")
            return {
                'contestacao': None,
                'erro': str(e),
                'sucesso': False
            }
        except Exception as e:
            print(f"‚ùå Erro inesperado: {e}\n")
            return {
                'contestacao': None,
                'erro': str(e),
                'sucesso': False
            }
    
    def regenerar_com_ajustes(
        self,
        resultado_anterior: Dict,
        ajustes: str,
        temperatura: Optional[float] = None,
        top_k: Optional[int] = None
    ) -> Dict:
        """
        Regenera contesta√ß√£o com ajustes solicitados pelo usu√°rio
        
        Args:
            resultado_anterior: Resultado da gera√ß√£o anterior
            ajustes: Instru√ß√µes de ajuste do usu√°rio
            temperatura: Nova temperatura (opcional)
            top_k: Novo top-k (opcional)
            
        Returns:
            Nova contesta√ß√£o gerada
        """
        # TODO: Implementar funcionalidade de regenera√ß√£o com feedback
        pass
